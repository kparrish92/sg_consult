---
title: "Updated Bayesian Ordinal Analysis"
output: html_document
format:
  html: 
    fig-format: svg
date: "2025-05-13"
---

```{r setup, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(here)
library(tidyverse)
library(jtools)
library(sjPlot)
library(lme4)
library(lmerTest)
library(ordinal)
library(bayesplot)
library(bayestestR)

td = read.csv(here("data", "ratings_tidy.csv")) %>% 
  filter(question_type != "old_directly_affected_questions")

```

## **RQ 1:** Does learning explicitly about bilingualism impact novice-intermediate L2 learnersâ€™ attitudes towards bilingualism and language learning? 

This one I don't think we can answer with the data (no pre/post design)

## **RQ 2:** How do the attitudes towards bilingualism and language learning differ between students who have received explicit instruction about bilingualism and those who have not? 

We have evidence that those with instruction answered more positively for directly affected questions, but not the other two.

#### Statistical Analysis 

An Bayesian Ordinal regression fit in R with `brms` with default priors with the cumulative family. Rating was predicted as a function of survey version (1 or 2) and question type (4 levels), with random intercepts for prompt and participant. The model was fit with 1000 warm-up and 2000 additional iterations across 4 processing cores. 

```{r, echo = FALSE, warning=FALSE, message=FALSE}
td$version = as.factor(td$version)

ord_mod_all = brms::brm(rating ~ version*question_type + current_class + (1 | prompt) + 
                       (1 | participant_number),
                     family = "cumulative",
                     data = td, 
                     file = here("data", "models", "ord_mod_no_daf.rds"))
```


#### Results 

```{r, warning = FALSE}
report_post = describe_posterior(
  ord_mod_all,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 2))
```

Figure 1 shows the distribution of ratings in each of the 3 question types in both versions 1 and 2. 
The bars represent the percentage of each answer choice in order to show comparable proportions rather than absolute numbers (since the group sizes were not equal).
The general trends show a right skewed distribution for the semi-affected questions, a left skew for directly affected questions, and a normal distribution for least affected questions. 

**Figure 1: The distribution of ratings by question type.**
```{r, fig_1, echo = FALSE, warning=FALSE, message=FALSE}
rating_ver = td %>% 
  group_by(version, question_type) %>% 
  summarise(n_t = n())

pct_df_preq_all = td %>%
  group_by(version, rating, question_type) %>% 
  summarise(n = n()) %>% 
  left_join(rating_ver) %>% 
  mutate(pct = n/n_t)

# Modify the data
pct_df_preq_all$question_type <- factor(pct_df_preq_all$question_type, levels = c("directly_affected_questions", "least_affected_questions", "semi_affected_questions"), 
                  labels = c("Directly affected questions", "Least affected questions", "Semi-affected questions"))

pct_df_preq_all$question_type_f = factor(pct_df_preq_all$question_type, levels=c('Directly affected questions','Semi-affected questions','Least affected questions'))


pct_df_preq_all %>% 
  filter(!is.na(question_type)) %>% 
  ggplot(aes(y = pct, x = rating, fill = as.factor(version))) + 
  geom_col(color = "black", position = "dodge") + 
  scale_fill_manual(values = c("#71797E", "seagreen")) +
  facet_grid(question_type_f~version) + theme_apa() + xlab("Rating choice") +
  ylab("Percentage of Ratings") + 
  theme(strip.text.y = element_text(angle = 0),
        legend.position = "none")
```

Table 1 describes posterior distributions of the Bayesian ordinal model, and corroborates the descriptive observations in Figure 1. The model contains five "intercepts" represent cut points in the probability space. If we think of the probability space as a rectangle with a given area that we "cut" into 5 pieces (one for each answer choice). The larger the area of the rectangle in a given piece directly responds to its probability as predicted by the model. That is, if the area of one of the five part of the great rectangle is .5 the area of the total (of the entire rectangle - or probability space), then we say that this the model predicts that the probability of that answer is also .5
The model, though, does not give the areas of the rectangle, but rather the exact location in which we would draw a vertical line to make one rectangle two conjoined ones. The long side of the rectangle is generally ranges from 0-1 in probability and the estimates tell us where (in log-odds), we can "draw" the first cut point. For example, `Intercept [1]` is the first cutoff point and represents the log-odds of a choice of 1 in the baseline condition.
The effect is `r report_post$Median[1]` (equal to a probability of `r round(plogis(report_post$Median[1]), digits = 2)`). We can interpret this as strong evidence that 1 is the most probable response in the baseline condition, and it suggests that the cutoff point could range from  `r report_post$CI_low[1]` (probability = `r round(plogis(report_post$CI_low[1]),digits = 2)`) to `r report_post$CI_high[1]` (probability `r round(plogis(report_post$CI_high[1]), digits = 2)`).

The fixed effect `b_version2` tells us the overall shift in ratings going from version 1 to version 2 in the baseline [95% HDI `r report_post$Median[5]`, `r report_post$CI_low[5]` - `r report_post$CI_high[5]`], and the probability of direction `r report_post$pd[5]`. 
Additionally, `b_current_class` did have a small impact on ratings, in which a one unit increase in class was associated with a change in `r report_post$Median[8]` log-odds [95% HDI `r report_post$CI_low[8]` - `r report_post$CI_high[8]`]. 

**Table 1: Summary of the posterior distribution**
```{r, warning = FALSE}
describe_posterior(
  ord_mod_all,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 2)) %>% 
  knitr::kable(row.names = FALSE)
```

There was not evidence that version was related differently for the semi-affected questions[`r report_post$Median[10]`; 95% HDI `r report_post$CI_low[10]` - `r report_post$CI_high[10]`] and the least affected questions 
[`r report_post$Median[9]`; 95% HDI `r report_post$CI_low[9]` - `r report_post$CI_high[9]`]. 
Vitally, by including the class level as a fixed effect, the other fixed effects and interaction terms are estimated with class level held constant. 
This suggests that the unequal proportions are not the cause of the compelling (significant) differences in other effects in the model.

Figure 2 visualizes the posterior distributions that are directly relevant to the research questions from Table 1. 
The distributions show the 95% range of plausible estimates for each effect with the shaded region representing 80% of plausible estimates.
It can be seen that all of these estimates do not overlap zero, except for directly affected questions. 

**Figure 2: The posterior distributions of the Bayesian Ordinal Model.**
```{r, fig_2, echo = FALSE, warning=FALSE, message=FALSE}
posterior <- as.matrix(ord_mod_all)

plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(posterior,
           pars = c("b_version2", "b_version2:question_typeleast_affected_questions", "b_version2:question_typesemi_affected_questions",
                    "b_current_class"),
           prob = 0.8) + plot_title +
  scale_y_discrete(limits = c("b_current_class",
  "b_version2:question_typeleast_affected_questions",
  "b_version2:question_typesemi_affected_questions",
                                       "b_version2")) + theme_minimal()

```


## **RQ 3:** Does learning explicitly about bilingualism impact students differently based on proficiency level?

> This model can be reported in the manuscript or made a supplementary analysis for an appendix. It's totally up to you since we have now included current_class in the main model, but I think this may not be needed any more. Let me know if you'd like a detailed interpretation of this model also.

It does not appear so - there is no evidence that class level impacted the size of the effect of having explicit instruction.


#### Statistical Analysis 

An Bayesian Ordinal regression fit in R with `brms` with default priors. Rating was predicted as a function of survey version (1 or 2) and current class (4 levels), with random intercepts for prompt and participant. 

```{r, warning = FALSE, message=FALSE}

td$current_class = as.factor(td$current_class)

ord_mod_class = brms::brm(rating ~ current_class*version + (1 | prompt) + 
                          (1 | participant_number),
                        family = "cumulative",
                        data = td, 
                        file = here("data", "models", "ord_mod_class.rds"))
```

```{r, fig_3, echo = FALSE, warning = FALSE, message=FALSE}
rating_ver_class = td %>% 
  group_by(version, current_class) %>% 
  summarise(n_t = n())

pct_df_preq_all_class = td %>%
  group_by(version, rating) %>% 
  summarise(n = n()) %>% 
  left_join(rating_ver_class) %>% 
  mutate(pct = n/n_t)

# Modify the data

pct_df_preq_all_class %>% 
  ggplot(aes(y = pct, x = rating, fill = as.factor(version))) + 
  geom_col(color = "black", position = "dodge") + 
  scale_fill_manual(values = c("#71797E", "seagreen")) +
  facet_grid(current_class~version) + theme_apa() + xlab("Rating choice") +
  ylab("Current Class") + 
  theme(strip.text.y = element_text(angle = 0),
        legend.position = "none")
```


```{r, fig_4, echo = FALSE, warning = FALSE, message=FALSE}
posterior_o<- as.matrix(ord_mod_class)

plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(posterior_o,
           pars = c("b_version", 
                    "b_current_class2:version", "b_current_class3:version", "b_current_class4:version"),
           prob = 0.8) + plot_title + theme_minimal()

```


